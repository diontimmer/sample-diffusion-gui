
[DEFAULTS]

#name of the run
name = dd-finetune

# training data directory
training_dir = ''

# the batch size
batch_size = 8 

# number of GPUs to use for training
num_gpus = 1 

# number of nodes to use for training
num_nodes = 1 

# number of CPU workers for the DataLoader
num_workers = 2

# Number of audio samples for the training input
sample_size = 65536 

# Number of steps between demos
demo_every = 1000

# Number of denoising steps for the demos       
demo_steps = 250

# Number of demos to create
num_demos = 16

# the EMA decay
ema_decay = 0.995       

# the random seed
seed = 42

# Batches for gradient accumulation
accum_batches = 4

# The sample rate of the audio
sample_rate = 48000   

# Number of steps between checkpoints
checkpoint_every = 10000                              

# unused, required by the model code
latent_dim = 0              

# If true training data is kept in RAM
cache_training_data = False  

# randomly crop input audio? (for augmentation)
random_crop = True 

# checkpoint file to (re)start training from
ckpt_path = ''

# Path to output the model checkpoints
save_path = ''

#the multiprocessing start method ['fork', 'forkserver', 'spawn']
start_method = 'spawn'

# Whether to save the model checkpoints to Weights & Biases
save_wandb = 'none'

# The max amount of epochs to run for training
max_epochs = 'none'